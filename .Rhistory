totalPage$link <- NULL
#抓出發文時間
totalPage$time <- substr(totalPage$created_time, start=12, stop=13)
str(totalPage)
#install.packages("ggplot2")
library(ggplot2)
ggplot(totalPage,aes(x=type,y=likes_count))+geom_boxplot()+theme_bw()
library(ggplot2)
dotchart(as.numeric(totalPage$time))
library(ggplot2)
dotchart(as.vector(as.numeric(totalPage$time)))
library(ggplot2)
dotchart(as.vector(totalPage$time))
library(ggplot2)
dotchart(as.factor(totalPage$time))
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAJaDO6YRZB83ZAmif6BVdAoNenKTia9ZCr1KoLGbTaciCCf0zr2RreV81B4OTRZCkCFZAgtGph5OIxqvZB75NYuwtCk39Fi8Ln8pSyf4X6cGWZBPAAQr9ZCCdoQhthZA75iKxBdDZALWZCK8hOCpfz0Om5R1lOuP61MSjmtSCFCRTjAIFjkPcvFxWgZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2017-05-21"),lastDate,by="1 days")  #以2016六月至今的貼文來做初步的分析
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
}
nrow(totalPage) #有幾筆資料
#先將不需要的欄位清除
totalPage$id <- NULL
totalPage$from_id <- NULL
totalPage$from_name <- NULL
totalPage$link <- NULL
#抓出發文時間
totalPage$time <- substr(totalPage$created_time, start=12, stop=13)
str(totalPage)
#install.packages("ggplot2")
library(ggplot2)
ggplot(totalPage,aes(x=type,y=likes_count))+geom_boxplot()+theme_bw()
library(ggplot2)
dotchart(as.numeric(totalPage$time))
mean(totalPage$likes_count)  #平均每篇貼文的讚數
mean(totalPage$comments_count) #下方留言平均數
mean(totalPage$shares_count) # 分享次篇貼文的次數
range(totalPage$shares_count)
library(dplyr)
totalpage_test <- NULL
totalpage_test <- totalPage
totalpage_test %>%
group_by(type) %>%
summarize(num_likes = mean(likes_count),
num_comment = mean(comments_count),
num_share  = mean(shares_count)) %>%
arrange(desc(num_likes))
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#新增詞彙
new_user_word(cutter,'並不是',"n")
new_user_word(cutter,'有一天',"n")
new_user_word(cutter,'點個頭',"v")
new_user_word(cutter,'不一定',"n")
new_user_word(cutter,'那一年',"n")
new_user_word(cutter,'花了',"v")
new_user_word(cutter,'不喜歡',"v")
new_user_word(cutter,'一開始',"n")
#自訂停止詞
readLines("stop.txt")
cutter = worker(stop_word ="stop.txt")
sort(table(cutter[totalPage$message]),decreasing = T)
head(sort(table(cutter[totalPage$message]),decreasing = T))
#install.packages("rJava")
#install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
#install.packages("tm")
#install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
#install.packages("wordcloud")
#install.packages("XML")
#install.packages("RCurl")
#install.packages("RPostgreSQL")
#devtools::install_github("lchiffon/wordcloud2")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
#Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
library(wordcloud2)
# 建立文本物件
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
install.packages("rJava")
install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
install.packages("tm")
install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
install.packages("wordcloud")
install.packages("XML")
install.packages("RCurl")
install.packages("rJava")
install.packages("tm")
install.packages("Rwordseg", repos = "http://R-Forge.R-project.org")
install.packages("tmcn", repos = "http://R-Forge.R-project.org", type = "source")
install.packages("wordcloud")
install.packages("XML")
install.packages("RPostgreSQL")
install.packages("tm")
devtools::install_github("lchiffon/wordcloud2")
install.packages("Rwordseg", repos = "http://R-Forge.R-project.org")
install.packages("tmcn", repos = "http://R-Forge.R-project.org", type = "source")
install.packages("XML")
install.packages("wordcloud")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
library(wordcloud2)
install.packages("tmcn", repos = "http://R-Forge.R-project.org", type = "source")
install.packages("XML")
install.packages("wordcloud")
install.packages("wordcloud")
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
wordsg <- totalPage$message
segmentCN(wordsg)
d<-data.frame(table(unlist(segmentCN(wordsg$message))),decreasing =T)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
d<-data.frame(table(unlist(segmentCN(totalPage$message))))
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
library(wordcloud2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
library(wordcloud2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
install.packages("rJava")
install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
install.packages("tm")
install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
install.packages("wordcloud")
install.packages("XML")
install.packages("RCurl")
install.packages("RPostgreSQL")
devtools::install_github("lchiffon/wordcloud2")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
# 建立文本物件
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))))
names(d)<-c("word","freq")
d$word<-as.character(d$word)
library(wordcloud2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
#install.packages("rJava")
#install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
#install.packages("tm")
#install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
#install.packages("wordcloud")
#install.packages("XML")
#install.packages("RCurl")
#install.packages("RPostgreSQL")
#devtools::install_github("lchiffon/wordcloud2")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
#Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
# 建立文本物件
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))))
names(d)<-c("word","freq")
d$word<-as.character(d$word)
library(wordcloud2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))))
names(d)<-c("word","freq")
d$word<-as.character(d$word)
library(wordcloud2)
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))))
names(d)<-c("word","freq")
d$word<-as.character(d$word)
library(wordcloud2)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
#install.packages("rJava")
#install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
#install.packages("tm")
#install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
#install.packages("wordcloud")
#install.packages("XML")
#install.packages("RCurl")
#install.packages("RPostgreSQL")
#devtools::install_github("lchiffon/wordcloud2")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
#Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
library(wordcloud2)
# 建立文本物件
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
if (length(colnames(db.stopwords)) > 0) {
my.stopwords <- c(stopwordsCN(), stopwords("english"), db.stopwords[,1])
} else {
my.stopwords <- c(stopwordsCN(), stopwords("english"))
}
segmentCN(totalPage$message)
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>2 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAO8ijwDZBQxLVhWXHbTKRwbKTV5kYIPdZAVJpMK1tomAZCgt67SancZAkO3JRrZCU7wRjAwyBAbRKuF1pS82woRrPZBVZBSP55AhITzvTuiFbHjbMW3CEZBogAnjFZB2qzmhp8TKZCTUT5dsqanFNqNllXPqn33dZBu8sjjZCdiqOMFgBtAK3HSCdYMZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2017-05-21"),lastDate,by="1 days")  #以2016六月至今的貼文來做初步的分析
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
}
head(segmentCN(totalPage$message))
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>2 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAO8ijwDZBQxLVhWXHbTKRwbKTV5kYIPdZAVJpMK1tomAZCgt67SancZAkO3JRrZCU7wRjAwyBAbRKuF1pS82woRrPZBVZBSP55AhITzvTuiFbHjbMW3CEZBogAnjFZB2qzmhp8TKZCTUT5dsqanFNqNllXPqn33dZBu8sjjZCdiqOMFgBtAK3HSCdYMZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2016-06-19"),lastDate,by="1 days")  #以2016六月至今的貼文來做初步的分析
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
}
nrow(totalPage) #有幾筆資料
#先將不需要的欄位清除
totalPage$id <- NULL
totalPage$from_id <- NULL
totalPage$from_name <- NULL
totalPage$link <- NULL
#抓出發文時間
totalPage$time <- substr(totalPage$created_time, start=12, stop=13)
str(totalPage)
#install.packages("ggplot2")
library(ggplot2)
ggplot(totalPage,aes(x=type,y=likes_count))+geom_boxplot()+theme_bw()
library(ggplot2)
dotchart(as.numeric(totalPage$time))
mean(totalPage$likes_count)  #平均每篇貼文的讚數
mean(totalPage$comments_count) #下方留言平均數
mean(totalPage$shares_count) # 分享次篇貼文的次數
range(totalPage$shares_count)
library(dplyr)
totalpage_test <- NULL
totalpage_test <- totalPage
totalpage_test %>%
group_by(type) %>%
summarize(num_likes = mean(likes_count),
num_comment = mean(comments_count),
num_share  = mean(shares_count)) %>%
arrange(desc(num_likes))
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#新增詞彙
new_user_word(cutter,'並不是',"n")
new_user_word(cutter,'有一天',"n")
new_user_word(cutter,'點個頭',"v")
new_user_word(cutter,'不一定',"n")
new_user_word(cutter,'那一年',"n")
new_user_word(cutter,'花了',"v")
new_user_word(cutter,'不喜歡',"v")
new_user_word(cutter,'一開始',"n")
#自訂停止詞
readLines("stop.txt")
cutter = worker(stop_word ="stop.txt")
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#install.packages("jiebaR")
library(jiebaR)
cutter2 <- worker()
cutter <- worker()
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAO8ijwDZBQxLVhWXHbTKRwbKTV5kYIPdZAVJpMK1tomAZCgt67SancZAkO3JRrZCU7wRjAwyBAbRKuF1pS82woRrPZBVZBSP55AhITzvTuiFbHjbMW3CEZBogAnjFZB2qzmhp8TKZCTUT5dsqanFNqNllXPqn33dZBu8sjjZCdiqOMFgBtAK3HSCdYMZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2017-01-01"),lastDate,by="1 days")  #以今年的貼文來做初步的分析
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
}
nrow(totalPage) #有幾筆資料
#先將不需要的欄位清除
totalPage$id <- NULL
totalPage$from_id <- NULL
totalPage$from_name <- NULL
totalPage$link <- NULL
#抓出發文時間
totalPage$time <- substr(totalPage$created_time, start=12, stop=13)
str(totalPage)
#install.packages("ggplot2")
library(ggplot2)
ggplot(totalPage,aes(x=type,y=likes_count))+geom_boxplot()+theme_bw()
library(ggplot2)
dotchart(as.numeric(totalPage$time))
mean(totalPage$likes_count)  #平均每篇貼文的讚數
mean(totalPage$comments_count) #下方留言平均數
mean(totalPage$shares_count) # 分享次篇貼文的次數
range(totalPage$shares_count)
library(dplyr)
totalpage_test <- NULL
totalpage_test <- totalPage
totalpage_test %>%
group_by(type) %>%
summarize(num_likes = mean(likes_count),
num_comment = mean(comments_count),
num_share  = mean(shares_count)) %>%
arrange(desc(num_likes))
#install.packages("jiebaR")
library(jiebaR)
cutter <- worker()
#新增詞彙
new_user_word(cutter,'並不是',"n")
new_user_word(cutter,'有一天',"n")
new_user_word(cutter,'點個頭',"n")
new_user_word(cutter,'不一定',"n")
new_user_word(cutter,'那一年',"n")
new_user_word(cutter,'花了',"n")
new_user_word(cutter,'不喜歡',"n")
new_user_word(cutter,'一開始',"n")
head(sort(table(cutter[totalPage$message]),decreasing = T))
#install.packages("rJava")
#install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
#install.packages("tm")
#install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
#install.packages("wordcloud")
#install.packages("XML")
#install.packages("RCurl")
#install.packages("RPostgreSQL")
#devtools::install_github("lchiffon/wordcloud2")
options(java.home="C:\\Program Files\\Java\\jre1.8.0_60")
#Sys.setenv(JAVA_HOME="C:\\Program Files\\Java\\jre1.8.0_60\\bin")
library(tm)
library(tmcn)
library(rJava)
library(Rwordseg) # 中文斷詞工具
library(wordcloud)
# 過濾器設定
library(XML)
library(wordcloud2)
# 建立文本物件
insertWords(toTrad(iconv(c("有一天","並不是","點個頭","不一定","那一年","花了","不喜歡","一開始"),
"big5", "UTF-8"), rev=TRUE))
db.stopwords<-data.frame(V1=c("了","的","https","goo","gl","peter","825","30","要","那就"))
db.stopwords$V1<-as.character(db.stopwords$V1)
if (length(colnames(db.stopwords)) > 0) {
my.stopwords <- c(stopwordsCN(), stopwords("english"), db.stopwords[,1])
} else {
my.stopwords <- c(stopwordsCN(), stopwords("english"))
}
head(segmentCN(totalPage$message))
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>4 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
View(d)
View(d)
head(segmentCN(totalPage$message))
d<-data.frame(table(unlist(segmentCN(totalPage$message)),decreasing =T))
d<-data.frame(table(unlist(segmentCN(totalPage$message))),decreasing =T)
names(d)<-c("word","freq")
d$word<-as.character(d$word)
wordcloud2(d[!d$word %in% my.stopwords & d$freq>5 & nchar(d$word)>1,],
fontFamily = "Microsoft JhengHei", minRotation = -pi/2, maxRotation = -pi/2)
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAO8ijwDZBQxLVhWXHbTKRwbKTV5kYIPdZAVJpMK1tomAZCgt67SancZAkO3JRrZCU7wRjAwyBAbRKuF1pS82woRrPZBVZBSP55AhITzvTuiFbHjbMW3CEZBogAnjFZB2qzmhp8TKZCTUT5dsqanFNqNllXPqn33dZBu8sjjZCdiqOMFgBtAK3HSCdYMZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2016-07-01"),lastDate,by="1 days")
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
}
?pause
?pause()
?Sys.sleep
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAEpZAs7Y9kTcrQhGeVCUoqmVH4Lgzk1LrDZBJHE2XsukVFoYZCcsTNETz2UlqjEMyoTJ96vtVyoHifM7Yy5hQfZCzZCcLNZAT6JbLxZAZCUpMNNZCiE45kYa3BRVRyV3SnR8ulO6TrnIh72rZBAnC55JvU1YwzjRXHk9xl9hKuFrvOH0jUvBgrH7IZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2017-05-01"),lastDate,by="3 days")
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
print(nrow(totalPage))
Sys.sleep(1)
}
install.packages("htmlwidgets")
install.packages("htmlwidgets")
devtools::install_github('ramnathv/htmlwidgets')
#install.packages("Rfacebook")
token<-"EAACEdEose0cBAEpZAs7Y9kTcrQhGeVCUoqmVH4Lgzk1LrDZBJHE2XsukVFoYZCcsTNETz2UlqjEMyoTJ96vtVyoHifM7Yy5hQfZCzZCcLNZAT6JbLxZAZCUpMNNZCiE45kYa3BRVRyV3SnR8ulO6TrnIh72rZBAnC55JvU1YwzjRXHk9xl9hKuFrvOH0jUvBgrH7IZD" #access token
library(Rfacebook)
lastDate<-Sys.Date()
DateVector<-seq(as.Date("2016-06-01"),lastDate,by="7 days")
DateVectorStr<-as.character(DateVector)
totalPage<-NULL
for(i in 1:(length(DateVectorStr)-1)){
tempPage<-getPage("petesonline", token,
since = DateVectorStr[i],
until = DateVectorStr[i+1])
totalPage<-rbind(totalPage,tempPage)
Sys.sleep(5)
}
